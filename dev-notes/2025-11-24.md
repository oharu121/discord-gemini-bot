# Dev Notes - 2025-11-24

## Project Overview

Discord bot that integrates with Google Gemini API to provide multimodal AI capabilities (text, image generation, video generation) through Discord chat interface.

---

## Current Implementation

### What the Script Achieves

The bot (bot.py) provides three main features:

1. **Text Generation / Chat** - Conversational AI with vision capabilities (can analyze attached images)
2. **Image Generation** - Creates images using Gemini/Imagen models
3. **Video Generation** - Creates videos using Veo models

### How It Works

#### Bot Architecture

```
Discord User Message
    |
    v
Discord Gateway (WebSocket)
    |
    v
discord.py library (handles protocol)
    |
    v
bot.on_message() event handler
    |
    v
process_message() - Routes based on keywords
    |
    v
GeminiClientWrapper - Makes API calls
    |
    v
Google Gemini API (text/image/video generation)
    |
    v
Response sent back through WebSocket
    |
    v
User sees result in Discord
```

#### Communication Flow Details

**Discord Bot Communication (No Webhooks/ngrok Needed!)**

The bot uses **persistent WebSocket connections**, not HTTP webhooks:

1. `bot.run(DISCORD_TOKEN)` establishes outbound WebSocket connection to Discord Gateway (wss://gateway.discord.gg)
2. Discord pushes events (messages, reactions, etc.) through this open connection
3. Bot sends responses back through the same WebSocket
4. **Key advantage**: No public IP, port forwarding, or ngrok required - the bot initiates the connection

**Why this works locally:**
- Bot connects TO Discord (outbound connection)
- WebSocket stays persistently open
- Discord pushes events in real-time
- Works behind NAT/firewalls since it's outbound-only

#### Request Routing (Current: Keyword-Based)

```python
# bot.py lines 173-217
if "video of" or "animate" in prompt:
    -> generate_video()
elif "image of" or "draw" in prompt:
    -> generate_image()
else:
    -> generate_text()
```

**Limitation**: Only works for English keywords, breaks with other languages (Chinese, Japanese, Spanish, etc.)

---

## How Components Work Together

### 1. discord.py Library

**What it does:**
- Abstracts Discord's REST API and WebSocket Gateway
- Handles authentication, rate limiting, reconnection
- Provides Pythonic methods that map to Discord API calls

**Examples:**

| Python Code | Discord API Call |
|-------------|------------------|
| `await message.reply("Hi")` | `POST /channels/{id}/messages` |
| `await message.add_reaction('eyes')` | `PUT /channels/{id}/messages/{id}/reactions/eyes/@me` |
| `async with message.channel.typing():` | `POST /channels/{id}/typing` (repeats every 5s) |
| `await attachment.read()` | `GET {cdn_url}` |
| `await message.remove_reaction('eyes', bot)` | `DELETE /channels/{id}/messages/{id}/reactions/eyes/@me` |

**Event Flow:**
```
Discord -> WebSocket EVENT -> discord.py parses -> Calls your on_message()
Bot Code -> discord.py method -> REST API call -> Discord servers
```

### 2. Google Gemini API

**Models Used:**
- `gemini-3-pro-preview` - Text generation and vision
- `gemini-3-pro-image-preview` or `imagen-3.0-*` - Image generation
- `veo-3.1-generate-preview` - Video generation

**API Interaction:**
```python
# Text/Vision
self.client.models.generate_content(
    model=MODEL_TEXT,
    contents=[image_part, text_prompt]
)

# Image
self.client.models.generate_images(
    model=MODEL_IMAGE,
    prompt=prompt
)

# Video (long-running operation)
operation = self.client.models.generate_videos(...)
while not operation.done:
    await asyncio.sleep(5)
    operation = self.client.operations.get(operation.name)
```

### 3. Integration Flow Example

**User mentions bot with "draw a cat":**

```
1. User types: "@YourBot draw a cat"
2. Discord sends MESSAGE_CREATE event via WebSocket
3. discord.py receives event, calls on_message(message)
4. Bot detects mention -> calls process_message()
5. Bot adds eyes reaction (feedback to user)
6. Keyword detection: "draw" -> image generation path
7. Bot adds art reaction
8. GeminiClientWrapper.generate_image("draw a cat")
9. Gemini API returns image bytes
10. Bot creates discord.File from bytes
11. Bot sends reply with file attachment
12. discord.py uploads file to Discord CDN
13. User sees generated image
```

---

## WebSocket vs SSE Comparison

### Server-Sent Events (SSE)

**How it works:**
```
Client -> Server: HTTP GET (opens connection)
Server -> Client: Event stream (one-way only)
Client -> Server: Separate HTTP POST for each message sent
```

**Characteristics:**
- [+] Simple to implement (just HTTP)
- [+] Works through most proxies/CDNs
- [+] Automatic reconnection
- [+] HTTP/2 multiplexing support
- [-] One-way only (server to client)
- [-] Text-based (need Base64 for binary)
- [-] Higher latency for two-way communication
- [-] Browser connection limits (6 per domain)

**Best for:**
- Live news feeds
- Stock tickers
- Server log monitoring
- Progress updates
- Notifications

### WebSocket

**How it works:**
```
Client <-> Server: Bidirectional persistent connection
Upgraded from HTTP to WebSocket protocol
Both sides can send/receive at any time
```

**Characteristics:**
- [+] Bidirectional (both can initiate)
- [+] Binary + text support
- [+] Lower latency
- [+] Minimal overhead after handshake
- [+] Built-in ping/pong for heartbeat
- [+] No connection limits
- [-] More complex to implement
- [-] Less proxy/CDN compatible

**Best for:**
- Chat applications
- Gaming
- Real-time collaboration
- Live dashboards
- Voice/video communication

### Why Discord Uses WebSocket

Discord bots need:
1. **Bidirectional communication** - Receive events AND send messages/reactions
2. **Low latency** - Instant typing indicators, reactions, presence updates
3. **High frequency** - Many rapid back-and-forth interactions
4. **Binary data** - Voice audio frames, efficient data transfer
5. **Heartbeat mechanism** - Discord requires regular ping/pong to keep connection alive

**Example scenario (bot processes message):**

**With SSE:**
```
1. Receive message (SSE stream) OK
2. HTTP POST to add eyes reaction
3. HTTP POST to start typing
4. HTTP POST to send reply
5. HTTP POST to remove eyes reaction
6. HTTP POST to add checkmark reaction
-> 5 separate HTTP requests + overhead
```

**With WebSocket (current):**
```
1. Receive message (WebSocket)
2. Send eyes reaction frame
3. Send typing frame
4. Send reply frame
5. Send remove eyes frame
6. Send checkmark reaction frame
-> 1 persistent connection, 5 lightweight frames
```

### Latency Comparison

```
SSE (two-way interaction):
Event arrives -> Process -> New HTTP request -> Wait for response
~50-200ms per action

WebSocket:
Event arrives -> Send frame through open socket
~10-50ms per action
```

---

## Future Improvements

### Problem: Language-Dependent Keyword Matching

Current implementation breaks with non-English input:

```python
# Current: Only works in English
if "video of" in prompt:
    generate_video()

# Fails for:
# Chinese: "generate cat video"
# Spanish: "genera un video de un gato"
# Japanese: "cat video make"
```

### Solution 1: Function Calling (Recommended)

Let the AI decide which tool to use based on understanding intent, not keywords.

**How it works:**

```python
# Define tools with descriptions
tools = [
    FunctionDeclaration(
        name="generate_video",
        description="Create a video or animation from description. Use when user wants moving images.",
        parameters={"prompt": "string"}
    ),
    FunctionDeclaration(
        name="generate_image",
        description="Create a static image, drawing, or painting.",
        parameters={"prompt": "string"}
    ),
    FunctionDeclaration(
        name="generate_text",
        description="Answer questions, have conversations, or analyze images.",
        parameters={"prompt": "string"}
    )
]

# Send to Gemini with tools
response = client.generate_content(
    model="gemini-2.0-flash",
    contents=prompt,
    tools=tools  # AI sees tool descriptions
)

# AI returns which function to call
function_call = response.function_call
if function_call.name == "generate_video":
    await generate_video(prompt)
```

**Benefits:**
- [+] Works in ANY language (AI understands intent)
- [+] More intelligent routing
- [+] Can handle complex requests ("make a video and then summarize it")
- [+] Relatively simple to implement

**Complexity:** Medium

### Solution 2: MCP (Model Context Protocol)

Standardized protocol for AI models to discover and use external tools dynamically.

#### MCP Concepts

**MCP Server:**
- A program that **provides tools** to AI models
- Exposes capabilities (read files, query database, generate media, etc.)
- Describes what each tool does
- Executes tool requests

**MCP Client:**
- A program (like our bot) that **uses tools** from MCP servers
- Asks servers "what tools do you have?"
- Lets AI see available tools
- Calls tools based on AI decisions
- Returns results to AI

**MCP Protocol:**
- Standardized communication between clients and servers
- Tool discovery (list available tools)
- Tool execution (call tool with parameters)
- Result handling

#### MCP Architecture Example

```
+--------------------------------------+
|    Discord Bot (MCP Client)         |
|                                      |
|  1. User: "@bot make cat video"     |
|  2. Ask servers: "What tools exist?" |
|  3. AI sees tool descriptions        |
|  4. AI decides: "Use generate_video" |
|  5. Call MCP server                  |
|  6. Return result to Discord         |
+--------------------------------------+
            | MCP Protocol
    +-------+-------+
    |               |
    v               v
+-----------+  +-----------+
|Gemini Srv |  |Discord Srv|
|           |  |           |
|-gen_video |  |-fetch_hist|
|-gen_image |  |-send_msg  |
|-gen_text  |  |-add_react |
+-----------+  +-----------+
```

#### Implementation Concept

**Create Gemini MCP Server:**
```python
# gemini_mcp_server.py
from mcp.server import Server

server = Server("gemini-generation")

@server.tool()
async def generate_video(prompt: str) -> bytes:
    """Generate a video from text description"""
    # Veo API call
    return video_bytes

@server.tool()
async def generate_image(prompt: str) -> bytes:
    """Generate an image from text description"""
    # Imagen API call
    return image_bytes

@server.tool()
async def generate_text(prompt: str) -> str:
    """Answer questions or analyze images"""
    # Gemini API call
    return response_text
```

**Bot becomes MCP Client:**
```python
# bot.py
from mcp.client import Client

class DiscordBot(discord.Client):
    def __init__(self):
        super().__init__(intents=discord.Intents.all())
        self.mcp = Client("http://localhost:3000")

    async def process_message(self, message):
        prompt = message.content

        # AI sees all available tools and their descriptions
        tools = await self.mcp.list_tools()

        # AI decides which tool to use (language-agnostic!)
        result = await self.mcp.execute_with_ai(
            prompt=prompt,
            tools=tools,
            model="gemini-2.0-flash"
        )

        await message.reply(result)
```

**Benefits:**
- [+] Works in ANY language
- [+] Dynamic tool discovery (add new MCP servers without changing bot code)
- [+] Separation of concerns (bot logic vs tool implementations)
- [+] Standardized protocol (reusable across projects)
- [+] AI makes intelligent decisions about tool usage

**Complexity:** High (requires MCP infrastructure)

---

## Comparison Table

| Approach | Language Support | Complexity | Intelligence | Flexibility |
|----------|------------------|------------|--------------|-------------|
| **Keywords** (current) | English only | Low | None | Low |
| **Function Calling** | All languages | Medium | High | Medium |
| **MCP** | All languages | High | High | Very High |

---

## Recommended Next Steps

1. **Implement Function Calling** (Priority: High)
   - Replace keyword detection with AI-powered tool selection
   - Supports all languages immediately
   - Moderate implementation effort

2. **Add Chat History Summary Feature** (Priority: Medium)
   ```python
   # Fetch messages
   messages = []
   async for msg in message.channel.history(limit=100):
       messages.append(f"{msg.author.name}: {msg.content}")

   # Send to Gemini for summary
   summary = await ai.generate_text("Summarize: " + "\n".join(messages))
   ```

3. **Explore MCP Integration** (Priority: Low/Future)
   - Research MCP SDK availability
   - Consider when you need multi-server architecture
   - Good for scaling to many external tools

---

## Key Learnings

1. **WebSocket != Webhook**: Discord bots use persistent WebSocket connections, not HTTP webhooks. No need for ngrok or public IPs.

2. **discord.py abstracts everything**: You never manually call Discord's REST API - the library handles all protocol details.

3. **Keyword matching is brittle**: Current approach only works in English. AI-powered tool selection is the modern solution.

4. **MCP is overkill for simple bots**: Function calling provides 80% of MCP benefits with 20% of the complexity.

5. **SSE vs WebSocket**: SSE is simpler but one-way. WebSocket is more complex but bidirectional and lower latency - essential for chat bots.

---

## References

- Discord Bot: bot.py
- Discord.py Docs: https://discordpy.readthedocs.io/
- Google Gemini API: https://ai.google.dev/
- MCP Specification: https://spec.modelcontextprotocol.io/
